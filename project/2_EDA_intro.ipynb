{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions to Answer\n",
    "\n",
    "1. How have the adjusted close prices of selected stocks (AAPL, MSFT, and GOOGL) trended over time?\n",
    "2. How do different sectors and industries perform in terms of returns and risk (volatility) over time?\n",
    "3. Which sectors exhibit the highest volatility, and when?\n",
    "4. What are the patterns in trading volume across different sectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Loading datasets\n",
    "file_path = r'C:\\Users\\hp\\.cache\\kagglehub\\datasets\\andrewmvd\\sp-500-stocks\\versions\\963\\sp500_stocks.csv'\n",
    "\n",
    "df_sp500 = pd.read_csv(file_path)\n",
    "df_companies = pd.read_csv(r'C:\\Users\\hp\\OneDrive\\Desktop\\Data_Analyst\\S&P_500\\sp500_data\\sp500_companies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleanup\n",
    "# Cleaning df_sp500\n",
    "# Convert Date to datetime format\n",
    "df_sp500['Date'] = pd.to_datetime(df_sp500['Date'])\n",
    "\n",
    "df_sp500['Symbol'] = df_sp500['Symbol'].astype('category')\n",
    "\n",
    "df_cleaned = df_sp500.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Datasets\n",
    "merged_df = pd.merge(df_cleaned, df_companies, on='Symbol', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging and Cleaning Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1773055 entries, 0 to 1773054\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   Date                 datetime64[ns]\n",
      " 1   Symbol               object        \n",
      " 2   Adj Close            float64       \n",
      " 3   Close                float64       \n",
      " 4   High                 float64       \n",
      " 5   Low                  float64       \n",
      " 6   Open                 float64       \n",
      " 7   Volume               float64       \n",
      " 8   Exchange             object        \n",
      " 9   Shortname            object        \n",
      " 10  Longname             object        \n",
      " 11  Sector               object        \n",
      " 12  Industry             object        \n",
      " 13  Currentprice         float64       \n",
      " 14  Marketcap            int64         \n",
      " 15  Ebitda               float64       \n",
      " 16  Revenuegrowth        float64       \n",
      " 17  City                 object        \n",
      " 18  State                object        \n",
      " 19  Country              object        \n",
      " 20  Fulltimeemployees    float64       \n",
      " 21  Longbusinesssummary  object        \n",
      " 22  Weight               float64       \n",
      "dtypes: datetime64[ns](1), float64(11), int64(1), object(10)\n",
      "memory usage: 311.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the merged datasets\n",
    "# Remove Duplicates\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median employee count per sector ()\n",
    "sector_medians = merged_df.groupby('Sector')['Fulltimeemployees'].transform('median')\n",
    "merged_df['Fulltimeemployees'] = merged_df['Fulltimeemployees'].fillna(sector_medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numerical columns are of the correct type\n",
    "numerical_type_cols = ['Currentprice', 'Marketcap', 'Volume', 'Weight']\n",
    "merged_df[numerical_type_cols] = merged_df[numerical_type_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Calculate Weekly Returns per Symbol\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Group by 'Symbol', set 'Date' as index, and resample weekly\u001b[39;00m\n\u001b[0;32m      6\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekly_Return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      7\u001b[0m     \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSymbol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdj Close\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW-MON\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpct_change\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 3: Calculate 30-day and 90-day Rolling Volatility for Daily Returns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily_Return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpct_change()\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:230\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[0;32m    225\u001b[0m     _apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, examples\u001b[38;5;241m=\u001b[39m_apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    227\u001b[0m     )\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1824\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, include_groups, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1822\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1824\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1826\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, Series)\n\u001b[0;32m   1827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1829\u001b[0m         ):\n\u001b[0;32m   1830\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1831\u001b[0m                 message\u001b[38;5;241m=\u001b[39m_apply_groupings_depr\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1832\u001b[0m                     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1835\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1836\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1885\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1885\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:919\u001b[0m, in \u001b[0;36mBaseGrouper.apply_groupwise\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[0;32m    918\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m--> 919\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    921\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Calculate Weekly Returns per Symbol\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Group by 'Symbol', set 'Date' as index, and resample weekly\u001b[39;00m\n\u001b[0;32m      6\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekly_Return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      7\u001b[0m     merged_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW-MON\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mffill()\u001b[38;5;241m.\u001b[39mpct_change())\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 3: Calculate 30-day and 90-day Rolling Volatility for Daily Returns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaily_Return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpct_change()\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\generic.py:9771\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   9768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9769\u001b[0m     convention \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 9771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_resampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSeries | DataFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9776\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9781\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9782\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\resample.py:2049\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_resampler\u001b[39m(obj: Series \u001b[38;5;241m|\u001b[39m DataFrame, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Resampler:\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;124;03m    Create a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2049\u001b[0m     tg \u001b[38;5;241m=\u001b[39m \u001b[43mTimeGrouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tg\u001b[38;5;241m.\u001b[39m_get_resampler(obj, kind\u001b[38;5;241m=\u001b[39mkind)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\resample.py:2138\u001b[0m, in \u001b[0;36mTimeGrouper.__init__\u001b[1;34m(self, obj, freq, key, closed, label, how, axis, fill_method, limit, kind, convention, origin, offset, group_keys, **kwargs)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convention \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m   2129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvention\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for `convention`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2132\u001b[0m     key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mindex, PeriodIndex)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   2135\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   2136\u001b[0m         key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2137\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2138\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m   2139\u001b[0m     )\n\u001b[0;32m   2140\u001b[0m ):\n\u001b[0;32m   2141\u001b[0m     freq \u001b[38;5;241m=\u001b[39m to_offset(freq, is_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\python_course\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "# Step 1: Reset the index to work with 'Date' as a regular column\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "# Step 2: Calculate Weekly Returns per Symbol\n",
    "# Group by 'Symbol', set 'Date' as index, and resample weekly\n",
    "merged_df['Weekly_Return'] = (\n",
    "    merged_df.groupby('Symbol')['Adj Close']\n",
    "    .apply(lambda x: x.resample('W-MON', on='Date').ffill().pct_change())\n",
    ")\n",
    "\n",
    "# Step 3: Calculate 30-day and 90-day Rolling Volatility for Daily Returns\n",
    "merged_df['Daily_Return'] = merged_df.groupby('Symbol')['Adj Close'].pct_change()\n",
    "merged_df['30D_Rolling_Volatility'] = (\n",
    "    merged_df.groupby('Symbol')['Daily_Return'].rolling(window=30).std().reset_index(level=0, drop=True)\n",
    ")\n",
    "merged_df['90D_Rolling_Volatility'] = (\n",
    "    merged_df.groupby('Symbol')['Daily_Return'].rolling(window=90).std().reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Step 4: Calculate Average Daily and Weekly Returns per Symbol\n",
    "avg_daily_return = merged_df.groupby('Symbol')['Daily_Return'].mean()\n",
    "avg_weekly_return = merged_df.groupby('Symbol')['Weekly_Return'].mean()\n",
    "\n",
    "# Optional: Calculate other financial ratios if applicable, like P/E and Dividend Yield\n",
    "# Ensure columns like 'EPS' and 'Dividend' are available in the DataFrame before computing these ratios\n",
    "if 'EPS' in merged_df.columns:\n",
    "    merged_df['P/E_Ratio'] = merged_df['Adj Close'] / merged_df['EPS']\n",
    "if 'Dividend' in merged_df.columns:\n",
    "    merged_df['Dividend_Yield'] = merged_df['Dividend'] / merged_df['Adj Close']\n",
    "\n",
    "# Display the first few rows to check calculations\n",
    "print(merged_df[['Symbol', 'Date', 'Adj Close', 'Weekly_Return', '30D_Rolling_Volatility', '90D_Rolling_Volatility']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = merged_df[merged_df.index.duplicated()]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with median values or Unknown where necessary \n",
    "\n",
    "#  Fill missing Ebitda values with the sector median\n",
    "merged_df['Ebitda'] = merged_df.groupby('Sector')['Ebitda'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Impute Revenuegrowth with sector median\n",
    "merged_df['Revenuegrowth'] = merged_df.groupby('Sector')['Revenuegrowth'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill missing states with a placeholder\n",
    "merged_df['State'] = merged_df['State'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns with limited unique values to 'category'\n",
    "categorical_columns = ['Sector', 'Industry', 'Exchange', 'State', 'Country']\n",
    "for col in categorical_columns:\n",
    "    merged_df[col] = merged_df[col].astype('category')\n",
    "\n",
    "# Check memory usage after conversion\n",
    "print(merged_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns by calculating the percentage change in Adj Close for each stock over time.\n",
    "\n",
    "merged_df['Daily_Return'] = merged_df.groupby('Symbol')['Adj Close'].pct_change()\n",
    "\n",
    "\n",
    "merged_df['30D_Rolling_Volatility'] = merged_df.groupby('Symbol')['Daily_Return'].rolling(window=30).std().reset_index(0, drop=True)\n",
    "# This line of code calculates the 30-day rolling volatility of daily returns for each symbol in the merged_df DataFrame\n",
    "# In summary, this code computes a new column in merged_df that contains the 30-day rolling volatility (standard deviation) of daily returns for each symbol, allowing you to analyze how the volatility of each asset changes over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate metrics by Sector with observed=True to silence the warning\n",
    "sector_summary = merged_df.groupby('Sector', observed=True).agg(\n",
    "    company_count=('Symbol', 'nunique'),\n",
    "    total_market_cap=('Marketcap', 'sum'),\n",
    "    avg_daily_return=('Daily_Return', 'mean'),\n",
    "    volatility_daily_return=('Daily_Return', 'std'),\n",
    "    max_price=('Currentprice', 'max'),\n",
    "    min_price=('Currentprice', 'min'),\n",
    "    total_volume=('Volume', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Aggregate metrics by Industry with observed=True\n",
    "industry_summary = merged_df.groupby('Industry', observed=True).agg(\n",
    "    company_count=('Symbol', 'nunique'),\n",
    "    total_market_cap=('Marketcap', 'sum'),\n",
    "    avg_daily_return=('Daily_Return', 'mean'),\n",
    "    volatility_daily_return=('Daily_Return', 'std'),\n",
    "    max_price=('Currentprice', 'max'),\n",
    "    min_price=('Currentprice', 'min'),\n",
    "    total_volume=('Volume', 'sum')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV for Power BI\n",
    "sector_summary.to_csv('sector_summary.csv', index=False)\n",
    "industry_summary.to_csv('industry_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('cleaned_merged_stock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Stock Trends\n",
    "- Plot stock price trends over time for selected companies to visualize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for symbol in merged_df['Symbol'].unique()[:5]:  # Adjust for number of stocks to plot\n",
    "    subset = merged_df[merged_df['Symbol'] == symbol]\n",
    "    plt.plot(subset['Date'], subset['Adj Close'], label=symbol)\n",
    "plt.title('Stock Price Trends for Selected Companies')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adjusted Close Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis:\n",
    "- Analyze daily returns and visualize average returns against volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_returns = merged_df.groupby('Symbol')['Daily_Return'].mean()\n",
    "volatility = merged_df.groupby('Symbol')['Daily_Return'].std()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(volatility, avg_returns)\n",
    "plt.title('Volatility vs Average Returns')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Average Daily Return')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector Performance:\n",
    "- Visualize the performance of different sectors if sector data is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sector performance with observed=False to silence the warning\n",
    "sector_performance = merged_df.groupby('Sector', observed=True)['Daily_Return'].mean().sort_values()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sector_performance.plot(kind='barh')\n",
    "plt.title('Average Daily Return by Sector')\n",
    "plt.xlabel('Average Daily Return')\n",
    "plt.ylabel('Sector')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(merged_df['Daily_Return'].dropna(), bins=50, alpha=0.7)\n",
    "plt.title('Histogram of Daily Returns')\n",
    "plt.xlabel('Daily Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
